---
title: "inDelphi exploration"
output:
  md_document:
    variant: markdown_github
---

```{r include=FALSE}
knitr::opts_chunk$set(echo=TRUE, message=FALSE, warning=FALSE, fig.width=10)
```

# inDelphi exploration on the dnSNP-Clinvar data

INTRO

## Load packages and data

First load the packages:

```{r load}
## For data manipulation
library(data.table) # good for big data
library(dplyr) # To manipulate/transform data.frames
library(magrittr) # pipes (e.g. %>%)
library(tidyr)

## For graphs and tables
library(ggplot2)
library(knitr)

## Functions
winsor <- function(x, u=10){
  ## Winsorize: if larger than u, force value to u
  if(any(x>u)) x[x>u] = u
  x
}
```

Then we'll read the input TSV file for the guides using the `fread` function.
Of note multiple guides might be present for each variant in the *guides* file but that is fine because we want to look at the inDelphi prediction for each cut.
This will create a *data.table* object which uses disk space rather than memory (if I understand correctly) so it's good for big data.
To reduce the amount of data loaded in R, let's only load some specific columns (using `select=`).

```{r read}
## Read the first row (headers) to remind us the order of each column
read.table('../scripts-dbSNP-ClinVar/mhcut-dbsnp-clinvar-deletion-indelphi5-guides.tsv.gz', nrows=1)
## Import variants and colums varL, mhL, mh1Dist, nbNMH, and the 5 inDelphi columns
gds = fread('gunzip -c ../scripts-dbSNP-ClinVar/mhcut-dbsnp-clinvar-deletion-indelphi5-guides.tsv.gz',
            select=c(20, 21, 27, 50, 57:61))
gds.df = as.data.frame(gds)
```

## Average predicted frequency across cell types

```{r mean}
gds.df$inDelphiFreqMean = rowMeans(as.matrix(gds.df[, 5:9]))
gds.df %>% head %>% kable
```

## Predicted frequency and variant size

```{r freq.vsize}
gds.df %>% mutate(varL=cut(varL, breaks=c(0,1,3,5,10,20,30,Inf))) %>%
  ggplot(aes(x=varL, y=inDelphiFreqMean)) +
  geom_violin(scale='width', fill='grey90') + geom_boxplot(alpha=0) + 
  theme_bw()
```

The average predicted frequencies tend to decrease when the variant gets too big (>10-20bp).
However, the variance increases with some large variants reaching high predicted frequencies.

## Predicted frequency and MH length

```{r freq.mhl}
gds.df %>% mutate(mhL=cut(mhL, breaks=c(0,1,3,5,10,20,30,Inf))) %>%
  ggplot(aes(x=mhL, y=inDelphiFreqMean)) +
  geom_violin(scale='width', fill='grey90') + geom_boxplot(alpha=0) + 
  theme_bw()
```

It's quite similar across different MH levels.

## Predicted frequency and nested MH

```{r freq.nmh}
gds.df %>% 
  mutate(nbNMH=cut(nbNMH, breaks=c(-Inf, 0,1,3,5,10,20,30,Inf))) %>%
  ggplot(aes(x=nbNMH, y=inDelphiFreqMean)) +
  geom_violin(scale='width', fill='grey90') + geom_boxplot(alpha=0) + 
  theme_bw()

```

The highest predicted frequency is nicely anti-correlated with the number of nested MH for the guide which have the least amount of nested MH.
That's good because that was one estimate used to get an idea of efficiency.

## Predicted frequency and distance between MH

```{r mhdist}
gds.df %>% 
  mutate(mh1Dist=factor(winsor(mh1Dist, 20))) %>%
  ggplot(aes(x=mh1Dist, y=inDelphiFreqMean)) +
  geom_violin(scale='width', fill='grey90') + geom_boxplot(alpha=0) + 
  theme_bw() + 
  xlab("MH distance (bp)") + ylab("median inDelphi prevalence (%)")+
  scale_x_discrete(breaks=c(0:20), labels=c(0:19,"20+")) +
  scale_y_continuous(name="inDelphi prevalence (%)")

mhdist.med = gds.df %>% mutate(mh1Dist=winsor(mh1Dist, 20)) %>%
  group_by(mh1Dist) %>% summarize_all(median, na.rm=TRUE)

mhdist.med %>% gather(celltype, freq, -mh1Dist, -varL, -mhL, -nbNMH, -inDelphiFreqMean) %>%
  mutate(celltype=gsub('inDelphiFreq','',celltype)) %>% 
  ggplot(aes(x=mh1Dist, y=freq, colour=celltype)) +
  geom_line() + scale_colour_brewer(palette='Set1') + 
  theme_bw() + 
  xlab("MH distance (bp)") + ylab("median inDelphi prevalence (%)")+
  scale_x_continuous(breaks=c(0:20), labels=c(0:19,"20+")) +
  scale_y_continuous(name="inDelphi prevalence (%)")

```
